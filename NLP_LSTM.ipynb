{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cElQEwpfq5FI",
        "outputId": "0a37c54a-5366-4bbd-cab5-d941a325ee99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.3)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas numpy nltk scikit-learn tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import nltk"
      ],
      "metadata": {
        "id": "Z1dBq0yqrDyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXUfoNa-rMQ6",
        "outputId": "493405d4-f8a0-4478-fd87-493db254c717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your dataset (assuming CSV format and that your dataset has 'processed_text' and 'label' columns)\n",
        "data = pd.read_csv('/content/train.csv')  # Replace 'your_dataset.csv' with your file path\n",
        "\n",
        "# Step 1: Data Cleaning\n",
        "data.dropna(subset=['crimeaditionalinfo'], inplace=True)\n",
        "data.drop_duplicates(inplace=True)\n",
        "\n",
        "# Check unique values in each column\n",
        "print(data['category'].value_counts())\n",
        "print(data['sub_category'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTk7g9r0rPUP",
        "outputId": "3f2a978e-b3e5-481c-9223-fe2ad5b260d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "category\n",
            "Online Financial Fraud                                  52496\n",
            "Online and Social Media Related Crime                   12076\n",
            "Any Other Cyber Crime                                   10811\n",
            "Cyber Attack/ Dependent Crimes                           3608\n",
            "Sexually Obscene material                                1764\n",
            "Hacking  Damage to computercomputer system etc           1709\n",
            "Sexually Explicit Act                                    1489\n",
            "Cryptocurrency Crime                                      473\n",
            "Online Gambling  Betting                                  444\n",
            "Child Pornography CPChild Sexual Abuse Material CSAM      357\n",
            "RapeGang Rape RGRSexually Abusive Content                 248\n",
            "Online Cyber Trafficking                                  183\n",
            "Cyber Terrorism                                           161\n",
            "Ransomware                                                 56\n",
            "Report Unlawful Content                                     1\n",
            "Name: count, dtype: int64\n",
            "sub_category\n",
            "UPI Related Frauds                                                      23526\n",
            "Other                                                                   10811\n",
            "DebitCredit Card FraudSim Swap Fraud                                    10044\n",
            "Internet Banking Related Fraud                                           8096\n",
            "Fraud CallVishing                                                        5780\n",
            "Cyber Bullying  Stalking  Sexting                                        4051\n",
            "EWallet Related Fraud                                                    4008\n",
            "FakeImpersonating Profile                                                2289\n",
            "Profile Hacking Identity Theft                                           2070\n",
            "Cheating by Impersonation                                                1980\n",
            "Unauthorised AccessData Breach                                           1113\n",
            "Online Job Fraud                                                          911\n",
            "DematDepository Fraud                                                     752\n",
            "Tampering with computer source documents                                  567\n",
            "Hacking/Defacement                                                        540\n",
            "Ransomware Attack                                                         534\n",
            "Malware Attack                                                            521\n",
            "SQL Injection                                                             508\n",
            "Denial of Service (DoS)/Distributed Denial of Service (DDOS) attacks      504\n",
            "Data Breach/Theft                                                         484\n",
            "Cryptocurrency Fraud                                                      473\n",
            "Online Gambling  Betting                                                  444\n",
            "Provocative Speech for unlawful acts                                      413\n",
            "Email Hacking                                                             349\n",
            "Business Email CompromiseEmail Takeover                                   290\n",
            "Online Trafficking                                                        183\n",
            "Cyber Terrorism                                                           161\n",
            "EMail Phishing                                                            157\n",
            "Online Matrimonial Fraud                                                  132\n",
            "Damage to computer computer systems etc                                   108\n",
            "Website DefacementHacking                                                  89\n",
            "Ransomware                                                                 56\n",
            "Impersonating Email                                                        44\n",
            "Intimidating Email                                                         29\n",
            "Against Interest of sovereignty or integrity of India                       1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Text Preprocessing\n",
        "# Define a function to clean text\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Lowercase text\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
        "    return text\n",
        "\n",
        "# Apply the function to the 'crimeaditionalinfo' column\n",
        "data['cleaned_text'] = data['crimeaditionalinfo'].apply(clean_text)"
      ],
      "metadata": {
        "id": "lqlOaVXqrS1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    tokens = text.split()\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    tokens = [stemmer.stem(token) for token in tokens]\n",
        "    return ' '.join(tokens)"
      ],
      "metadata": {
        "id": "c9le6IJJrWMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['processed_text'] = data['cleaned_text'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "aF0ajlPprZjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for neural network\n",
        "X = data['processed_text']\n",
        "y = data['category']"
      ],
      "metadata": {
        "id": "rbd2CTEqrbJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)"
      ],
      "metadata": {
        "id": "Bic_jA4hrtb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X)\n",
        "X_seq = tokenizer.texts_to_sequences(X)"
      ],
      "metadata": {
        "id": "hPlD1qlkrvXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding sequences\n",
        "max_length = max(len(seq) for seq in X_seq)\n",
        "X_pad = pad_sequences(X_seq, maxlen=max_length)"
      ],
      "metadata": {
        "id": "gll72QGIrxkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pad, y_encoded, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "0AOeNbj_r0pN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the Neural Network model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=128, input_length=max_length))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(len(label_encoder.classes_), activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7utRiaJ4r3OX",
        "outputId": "24245060-ba5c-43b9-e75c-45b7b0ae510b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "SD2rUR-Or5YH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9By7w-Xr7zg",
        "outputId": "02445bc1-7849-4752-a3b3-73c8e64360e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2147/2147 - 730s - 340ms/step - accuracy: 0.7339 - loss: 0.7923 - val_accuracy: 0.7386 - val_loss: 0.7632\n",
            "Epoch 2/20\n",
            "2147/2147 - 740s - 344ms/step - accuracy: 0.7529 - loss: 0.7181 - val_accuracy: 0.7459 - val_loss: 0.7376\n",
            "Epoch 3/20\n",
            "2147/2147 - 768s - 358ms/step - accuracy: 0.7662 - loss: 0.6735 - val_accuracy: 0.7443 - val_loss: 0.7468\n",
            "Epoch 4/20\n",
            "2147/2147 - 769s - 358ms/step - accuracy: 0.7792 - loss: 0.6372 - val_accuracy: 0.7417 - val_loss: 0.7598\n",
            "Epoch 5/20\n",
            "2147/2147 - 755s - 351ms/step - accuracy: 0.7902 - loss: 0.6071 - val_accuracy: 0.7399 - val_loss: 0.7657\n",
            "Epoch 6/20\n",
            "2147/2147 - 737s - 343ms/step - accuracy: 0.8008 - loss: 0.5762 - val_accuracy: 0.7330 - val_loss: 0.7900\n",
            "Epoch 7/20\n",
            "2147/2147 - 738s - 344ms/step - accuracy: 0.8096 - loss: 0.5451 - val_accuracy: 0.7331 - val_loss: 0.8205\n",
            "Epoch 8/20\n",
            "2147/2147 - 743s - 346ms/step - accuracy: 0.8194 - loss: 0.5205 - val_accuracy: 0.7272 - val_loss: 0.8379\n",
            "Epoch 9/20\n",
            "2147/2147 - 744s - 347ms/step - accuracy: 0.8283 - loss: 0.4957 - val_accuracy: 0.7215 - val_loss: 0.8688\n",
            "Epoch 10/20\n",
            "2147/2147 - 744s - 346ms/step - accuracy: 0.8365 - loss: 0.4713 - val_accuracy: 0.7201 - val_loss: 0.9202\n",
            "Epoch 11/20\n",
            "2147/2147 - 748s - 348ms/step - accuracy: 0.8444 - loss: 0.4487 - val_accuracy: 0.7221 - val_loss: 0.9431\n",
            "Epoch 12/20\n",
            "2147/2147 - 735s - 342ms/step - accuracy: 0.8512 - loss: 0.4293 - val_accuracy: 0.7118 - val_loss: 0.9733\n",
            "Epoch 13/20\n",
            "2147/2147 - 732s - 341ms/step - accuracy: 0.8580 - loss: 0.4108 - val_accuracy: 0.7149 - val_loss: 1.0139\n",
            "Epoch 14/20\n",
            "2147/2147 - 748s - 349ms/step - accuracy: 0.8634 - loss: 0.3940 - val_accuracy: 0.7168 - val_loss: 1.0513\n",
            "Epoch 15/20\n",
            "2147/2147 - 729s - 339ms/step - accuracy: 0.8689 - loss: 0.3789 - val_accuracy: 0.7129 - val_loss: 1.0641\n",
            "Epoch 16/20\n",
            "2147/2147 - 761s - 355ms/step - accuracy: 0.8731 - loss: 0.3650 - val_accuracy: 0.7117 - val_loss: 1.0877\n",
            "Epoch 17/20\n",
            "2147/2147 - 755s - 352ms/step - accuracy: 0.8754 - loss: 0.3530 - val_accuracy: 0.7053 - val_loss: 1.1178\n",
            "Epoch 18/20\n",
            "2147/2147 - 695s - 324ms/step - accuracy: 0.8830 - loss: 0.3394 - val_accuracy: 0.7070 - val_loss: 1.1658\n",
            "Epoch 19/20\n",
            "2147/2147 - 699s - 326ms/step - accuracy: 0.8873 - loss: 0.3281 - val_accuracy: 0.7046 - val_loss: 1.1878\n",
            "Epoch 20/20\n",
            "2147/2147 - 742s - 345ms/step - accuracy: 0.8899 - loss: 0.3185 - val_accuracy: 0.7027 - val_loss: 1.2048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "y_pred = np.argmax(model.predict(X_test), axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uk9-ePTdr-Vc",
        "outputId": "20183b4e-cfa9-4709-9cad-b4a03fdbc277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 114ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the labels actually present in y_test\n",
        "labels = np.unique(y_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Neural Network Model Evaluation:\")\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred):.4f}')\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, y_pred, labels=labels, target_names=label_encoder.classes_[labels]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuIvvNdV55XR",
        "outputId": "d3a20269-416a-4709-fd57-7a79229830ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural Network Model Evaluation:\n",
            "Accuracy: 0.7027\n",
            "Classification Report:\n",
            "                                                      precision    recall  f1-score   support\n",
            "\n",
            "                               Any Other Cyber Crime       0.35      0.34      0.35      2116\n",
            "Child Pornography CPChild Sexual Abuse Material CSAM       0.42      0.26      0.32        68\n",
            "                                Cryptocurrency Crime       0.56      0.43      0.49        95\n",
            "                      Cyber Attack/ Dependent Crimes       1.00      1.00      1.00       718\n",
            "                                     Cyber Terrorism       0.00      0.00      0.00        44\n",
            "      Hacking  Damage to computercomputer system etc       0.34      0.31      0.32       375\n",
            "                            Online Cyber Trafficking       0.00      0.00      0.00        36\n",
            "                              Online Financial Fraud       0.83      0.86      0.85     10520\n",
            "                            Online Gambling  Betting       0.15      0.09      0.11        91\n",
            "               Online and Social Media Related Crime       0.51      0.53      0.52      2414\n",
            "                                          Ransomware       0.00      0.00      0.00        13\n",
            "           RapeGang Rape RGRSexually Abusive Content       0.05      0.02      0.03        43\n",
            "                               Sexually Explicit Act       0.11      0.05      0.07       300\n",
            "                           Sexually Obscene material       0.21      0.17      0.19       343\n",
            "\n",
            "                                            accuracy                           0.70     17176\n",
            "                                           macro avg       0.32      0.29      0.30     17176\n",
            "                                        weighted avg       0.69      0.70      0.69     17176\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_category(user_input):\n",
        "    # Step 1: Preprocess the input\n",
        "    cleaned_input = clean_text(user_input)\n",
        "    processed_input = preprocess_text(cleaned_input)\n",
        "\n",
        "    # Step 2: Tokenize and pad the input to match the LSTM input format\n",
        "    input_seq = tokenizer.texts_to_sequences([processed_input])\n",
        "    input_pad = pad_sequences(input_seq, maxlen=max_length)  # Ensure the same max_length as during training\n",
        "\n",
        "    # Step 3: Predict the category\n",
        "    prediction = model.predict(input_pad)\n",
        "    predicted_category_index = np.argmax(prediction, axis=1)[0]\n",
        "    predicted_category = label_encoder.inverse_transform([predicted_category_index])[0]\n",
        "\n",
        "    return predicted_category"
      ],
      "metadata": {
        "id": "n_ecUIBWWWsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User input Testing\n",
        "user_input = input(\"Enter your complaint: \")\n",
        "predicted_category = predict_category(user_input)\n",
        "print(f\"Predicted Category: {predicted_category}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7d6W6G_WXV2",
        "outputId": "beea20ea-ed14-4ab6-c431-df8bcd1c5739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your complaint: My starmaker id was hacked and used another person  My account name  Sonai Das Id sonai Id mobile nu    Full name Sonamoni Das  address Ukhra krishna chura pallyPaschim Bardhaman West bengal \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "Predicted Category: Online and Social Media Related Crime\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wUtcFKbiWlK_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}